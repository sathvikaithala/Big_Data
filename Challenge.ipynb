{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5OCYaS4_u37"
      },
      "source": [
        "# Big Data\n",
        "\n",
        "UC Berkeley Extension Data Analytics Boot Camp Module 16 Challenge\n",
        "\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy364XiZAMay"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "In this assignment, we were tasked with running the ETL process on the cloud, using Spark. We utilized PySpark to run statistical analysis on a database of US-based Amazon.com reviews for cameras. \n",
        "\n",
        "\n",
        "We first created our tables in the RDS database. We then extracted the data from the S3 bucket and loaded it into a dataframe. Once the data was in a DataFrame, we transformed it to fit the desired schema (from schema.sql). To complete the ETL process, we loaded the DataFrames that correspond to tables into an RDS instance.\n",
        "\n",
        "\n",
        "Once the ETL process was completed, we performed statistical analyses in PySpark to determine if the Vine reviews were unbiased.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDCM6036Bv93"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw1SlwG0_8Zk",
        "outputId": "a55c7f50-c021-4407-c32d-4cd39186ca83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Java, Spark, and Findspark\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4SkjJmTBshU",
        "outputId": "5dcac504-e337-4716-bfa4-0325745183a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# set up postgres\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-15 21:26:41--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  1.02MB/s    in 0.9s    \n",
            "\n",
            "2020-10-15 21:26:43 (1.02 MB/s) - ‘postgresql-42.2.9.jar’ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cRsJ1PIAa_f"
      },
      "source": [
        "# pyspark setup\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"ChallengeETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyouYE5rCGR3"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## ETL Process\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejaWo_BuNfKK"
      },
      "source": [
        "### Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjhE4lKmB6Oz",
        "outputId": "73a1dc7e-af2b-40e5-9f7b-051ef3f2bee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# link to camera reviews: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz\n",
        "\n",
        "# structure:\n",
        "# marketplace       - 2 letter country code of the marketplace where the review was written.\n",
        "# customer_id       - Random identifier that can be used to aggregate reviews written by a single author.\n",
        "# review_id         - The unique ID of the review.\n",
        "# product_id        - The unique Product ID the review pertains to. In the multilingual dataset the reviews\n",
        "#                     for the same product in different countries can be grouped by the same product_id.\n",
        "# product_parent    - Random identifier that can be used to aggregate reviews for the same product.\n",
        "# product_title     - Title of the product.\n",
        "# product_category  - Broad product category that can be used to group reviews \n",
        "#                     (also used to group the dataset into coherent parts).\n",
        "# star_rating       - The 1-5 star rating of the review.\n",
        "# helpful_votes     - Number of helpful votes.\n",
        "# total_votes       - Number of total votes the review received.\n",
        "# vine              - Review was written as part of the Vine program.\n",
        "# verified_purchase - The review is on a verified purchase.\n",
        "# review_headline   - The title of the review.\n",
        "# review_body       - The review text.\n",
        "# review_date       - The date the review was written.\n",
        "\n",
        "url =\"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "raw_camera_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"amazon_reviews_us_Camera_v1_00.tsv.gz\"), sep=\"\\t\", header=True, inferSchema=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2dc165d2d782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mraw_camera_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparkFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amazon_reviews_us_Camera_v1_00.tsv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f-LJIq8Dttq"
      },
      "source": [
        "---\n",
        "\n",
        "### Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv-1AhshDu8d",
        "outputId": "60450302-8ce5-4f9d-8ec4-476fad5dabc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# Inspect\n",
        "\n",
        "raw_camera_df.show(5)\n",
        "\n",
        "print(f\"There are \", raw_camera_df.count(), \" rows in this dataset \\n\")\n",
        "\n",
        "raw_camera_df.printSchema()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1d2ce7913b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_camera_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There are \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_camera_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" rows in this dataset \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_camera_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaxIlnucG08j"
      },
      "source": [
        "The schema of the data does not our desired schema. However, the data types match. Next, we need to check for null values within the reviews. Once the null values are removed, we can work on matching the schemas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIqQ4CPTGg2o"
      },
      "source": [
        "# Drop nulls\n",
        "\n",
        "camera_df = raw_camera_df.dropna()\n",
        "\n",
        "print(f\"There are \", camera_df.count(),\" values once the nulls are dropped.\\n\")\n",
        "\n",
        "camera_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFH--XBnG9wi"
      },
      "source": [
        "We found that there were 125 null values. The camera_df DataFrame houses the cleaned, non-null data that we will further transform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2ApaohLEJwQ"
      },
      "source": [
        "Desired Schema:\n",
        "\n",
        "--- \n",
        "\n",
        "review_id_table:\n",
        "\n",
        "|Column|Data Type|\n",
        "|-----|-------|\n",
        "|review_id|text|\n",
        "|customer_id|integer|\n",
        "|product_id|text|\n",
        "|product_parent|integer|\n",
        "|review_date|date (yyyy-mm-dd)|\n",
        "\n",
        "---\n",
        "\n",
        "products:\n",
        "\n",
        "|Column|Data Type|\n",
        "|------|--------|\n",
        "|product_id (unique)|text|\n",
        "|product_text|text|\n",
        "\n",
        "---\n",
        "\n",
        "customers:\n",
        "\n",
        "|Column|Data Type|\n",
        "|-----|-------|\n",
        "|customer_id (unique)|integer|\n",
        "|customer_count|integer|\n",
        "\n",
        "---\n",
        "\n",
        "vine_table: \n",
        "\n",
        "|Column|Data Type|\n",
        "|-----|-------|\n",
        "|review_id|text|\n",
        "|star_rating|integer|\n",
        "|helpful_votes|integer|\n",
        "|total_votes|integer|\n",
        "|vine|text|\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmpUG-2kEGbM"
      },
      "source": [
        "# create review_id_table DF:\n",
        "\n",
        "review_id_table_df = camera_df.select(['review_id', 'customer_id', 'product_id', 'product_parent', 'review_date'])\n",
        "review_id_table_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rjUFDeGGL0q"
      },
      "source": [
        "# create products DF:\n",
        "\n",
        "products_df = camera_df.select(['product_id', 'product_title']).distinct()\n",
        "products_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNzG6lWXIYHc"
      },
      "source": [
        "# create customers DF:\n",
        "\n",
        "# First we must create the customer_count column (as integers)\n",
        "\n",
        "# Load in a sql function to use column functions\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "camera_df = camera_df.withColumn('customer_count', sum((camera_df['customer_id']>0).cast('integer') for col in camera_df.groupby().count())) \n",
        "\n",
        "\n",
        "customers_df = camera_df.select(['customer_id','customer_count'])\n",
        "customers_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AyJAFJNI1OW"
      },
      "source": [
        "# create vine_table DF:\n",
        "\n",
        "vine_table_df = camera_df.select(['review_id', 'star_rating', 'helpful_votes', 'total_votes','vine'])\n",
        "vine_table_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY8tSp5bNvad"
      },
      "source": [
        "Now, all our tables match the schema we want. We are done with the transformation process, and are ready to move on to the loading process.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "### Load:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BktuZtHnNuxs"
      },
      "source": [
        "# Setup RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://AWS_Challenge16.c4brwagnxkub.us-east-2.rds.amazonaws.com:5432/challenge16\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": \"Module16\", \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytIfJDfZQUjf"
      },
      "source": [
        "# Load the DataFrames as tables in RDS\n",
        "\n",
        "# review_id_table:\n",
        "review_id_table_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)\n",
        "\n",
        "# products:\n",
        "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)\n",
        "\n",
        "# customers:\n",
        "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)\n",
        "\n",
        "# vine_table:\n",
        "vine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWMGhNibOPy1"
      },
      "source": [
        "We have sucessfully completed the loading process. Now, we can move on to analysis.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## Analysis\n",
        "\n",
        "The goal of our analysis is to determine whether Vine reviews are biased or not for the cameras listed on Amazon. We will do this via various statistical methods.\n",
        "\n",
        "First, we need to separate the Vine reviews from the non-Vine reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD_T1b9_hL0g",
        "outputId": "0bed9259-c67a-4549-cb4d-bd7c4d1e87c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# create DataFrames for Vine and Non-Vine reviews\n",
        "\n",
        "\n",
        "vine_only_df = vine_table_df.filter(vine_table_df[\"vine\"] == \"N\")\n",
        "non_vine_df = vine_table_df.filter(vine_table_df[\"vine\"] == \"Y\")\n",
        "\n",
        "vine_only_df.show(5)\n",
        "non_vine_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R1NBG94582SJE2|          5|            0|          0|   N|\n",
            "|R273DCA6Y0H9V7|          5|            0|          0|   N|\n",
            "| RQVOXO7WUOFK6|          2|            1|          1|   N|\n",
            "|R1KWKSF21PO6HO|          5|            0|          0|   N|\n",
            "|R38H3UO1J190GI|          5|            1|          1|   N|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R2H4QESQ10P8EN|          5|            4|          5|   Y|\n",
            "|  RY5OEUWERD2Z|          4|            5|          5|   Y|\n",
            "|R3GNSMDV7WZGKP|          4|            1|          1|   Y|\n",
            "|R1RI2CNUVSAOU6|          4|            0|          0|   Y|\n",
            "|R3UX0VTCK4SUJX|          4|            0|          0|   Y|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_uYiWmijDRP"
      },
      "source": [
        "Now that we have separated the data into Vine and Non-Vine reviews, we can perform statistical analysis on both DataFrames to determine whether there is bias in the Vine reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q_yMqcDlLx5",
        "outputId": "59bb622b-ded6-4a0c-edbf-c8fd2d62124e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the number of reviews in each set\n",
        "\n",
        "print(f\"There are \",vine_only_df.count(),\" paid reviews, compared to \", non_vine_df.count(),\" non-paid reviews.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are  1793966  paid reviews, compared to  7883  non-paid reviews.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvQ_X36F7i2P"
      },
      "source": [
        "We can see that a majority of the reviews are from the Vine cohort by a very large margin. While this does not imply any biases, it is worth looking into in more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH273kZ_OoVo",
        "outputId": "25c19035-dcc9-49db-8b0d-34db16870685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# calculate the average rating\n",
        "\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "print(\"In the Non-Vine data set, the average rating is:\")\n",
        "non_vine_df.select(avg(\"star_rating\")).show()\n",
        "\n",
        "print(\"In the Vine data set, the average rating is:\")\n",
        "vine_only_df.select(avg(\"star_rating\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the Non-Vine data set, the average rating is:\n",
            "+-----------------+\n",
            "| avg(star_rating)|\n",
            "+-----------------+\n",
            "|4.128250665990105|\n",
            "+-----------------+\n",
            "\n",
            "In the Vine data set, the average rating is:\n",
            "+-----------------+\n",
            "| avg(star_rating)|\n",
            "+-----------------+\n",
            "|4.127021916803328|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLB2rY0jMcb"
      },
      "source": [
        "We see that the average review score for both Vine and Non-Vine data sets are both around 4.13 out of 5. Based on this alone, we cannot claim that the Vine data set shows bias. \n",
        "\n",
        "Now we can compare each set's share of 1 to 5 star ratings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9LQb0HWilFU",
        "outputId": "51ecd6d5-3a7c-4deb-e6fd-5aac320f0859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# See a breakdown of ratings for each set.\n",
        "\n",
        "print(f\"\", \"%.1f\"% (vine_only_df.filter(\"star_rating=1\").count()/vine_only_df.count()*100),\"% of the Vine reviews were rated 1 star, compared to \", \"%.1f\"% (non_vine_df.filter(\"star_rating=1\").count()/non_vine_df.count()*100),\"% of Non-Vine 1 star ratings.\")\n",
        "print(f\"\", \"%.1f\"% (vine_only_df.filter(\"star_rating=2\").count()/vine_only_df.count()*100),\"% of the Vine reviews were rated 2 stars, compared to \", \"%.1f\"% (non_vine_df.filter(\"star_rating=2\").count()/non_vine_df.count()*100),\"% of Non-Vine 2 star ratings.\")\n",
        "print(f\"\", \"%.1f\"% (vine_only_df.filter(\"star_rating=3\").count()/vine_only_df.count()*100),\"% of the Vine reviews were rated 3 stars, compared to \", \"%.1f\"% (non_vine_df.filter(\"star_rating=3\").count()/non_vine_df.count()*100),\"% of Non-Vine 3 star ratings.\")\n",
        "print(f\"\", \"%.1f\"% (vine_only_df.filter(\"star_rating=4\").count()/vine_only_df.count()*100),\"% of the Vine reviews were rated 4 stars, compared to \", \"%.1f\"% (non_vine_df.filter(\"star_rating=4\").count()/non_vine_df.count()*100),\"% of Non-Vine 4 star ratings.\")\n",
        "print(f\"\", \"%.1f\"% (vine_only_df.filter(\"star_rating=5\").count()/vine_only_df.count()*100),\"% of the Vine reviews were rated 5 stars, compared to \", \"%.1f\"% (non_vine_df.filter(\"star_rating=5\").count()/non_vine_df.count()*100),\"% of Non-Vine 5 star ratings.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 9.5 % of the Vine reviews were rated 1 star, compared to  1.8 % of Non-Vine 1 star ratings.\n",
            " 5.0 % of the Vine reviews were rated 2 stars, compared to  4.5 % of Non-Vine 2 star ratings.\n",
            " 7.8 % of the Vine reviews were rated 3 stars, compared to  14.4 % of Non-Vine 3 star ratings.\n",
            " 18.6 % of the Vine reviews were rated 4 stars, compared to  37.4 % of Non-Vine 4 star ratings.\n",
            " 59.1 % of the Vine reviews were rated 5 stars, compared to  41.8 % of Non-Vine 5 star ratings.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nOGnvpS50G0"
      },
      "source": [
        "We see that there are more 5 star reviews for the Vine reviews than for the Non-Vine reviews. However, there are also more 1 star reviews as well. \n",
        "\n",
        "#### Conclusion:\n",
        "\n",
        "Given the much larger number of responses in the Vine set than the non-paid Non-Vine set, we would expect to see the average ratings for the Vine set to be much higher than the Non-Vine set. However, this does not appear to be the case. We can conclude that the reviews for the Camera dataset do not show any significant bias towards the paid Vine reviews, and they are trustworthy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MCnJlVG6cRL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}